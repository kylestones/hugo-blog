#+TITLE:          AutoML
#+AUTHOR:         Kyle Three Stones
#+DATE:           <2019-05-04 Sat>
#+EMAIL:          kyleemail@163.com
#+OPTIONS:        H:3 num:t toc:nil \n:nil @:t ::t |:t ^:t f:t tex:t
#+TAGS:           AutoML, 深度学习
#+CATEGORIES:     深度学习


就像使用 CNN 提取特征来代替人工设计的特征，使用 AutoML 代替人设计网络的架构，应该是可以达到更好的效果。


** 前提

CNN 通常需要大量的时间来设计网络的架构。当然我们可以使用迁移学习，但是 *只有针对数据集设计自己的网络才能达到最好的性能*
。然而设计网络架构需要专业的技能，且具有很大的挑战（对于商业应用来说代价太大）。


** NAS

Neural Architecture Search 就是用于搜索最优网络架构的算法。提供了深度学习的一个新的研究方向。

1. 定义候选 building blocks
1. 使用一个 RNN 作为控制器，用于选择拼装 building blocks
1. 在交叉验证集上，训练拼装好的网络，使其收敛
1. 根据网络的准确率来更新 RNN 控制器（update with policy gradient），希望其能选择出更好的网络架构

In simple terms: have an algorithm grab diierent blocks and put those blocks together to make a network. Train and test
out that network. Based on your results, adjust the blocks you used to make the network and how you put them together!
It’s a fairly intuitive approach!

算法成功的原因：

1. 在一个很小的数据集上测试
1. 搜索空间很有限

NASNet paper 提出了一个新的研究方向，但是其效率太低，需要 450 块 GPUs 耗费 3-4 的时间才能训练好。大部分最近的研究都是在
提高 NAS 的效率。就像提高 CNN 的训练效率一样，训练效率对于科研和实用都非常重要。

附：
1. 在深度学习领域，一个网络架构在小的数据集表现优异，那么相似的架构在大的数据集上表现也不错。


*** PNAS

使用 a sequential model-based optimisation (SMBO) strategy 而不是 reinforcement learning 。

其理念大致是： instead of trying everything all at once, let’s start off simple and only get complex if we need to 。

可以提高 5-8 倍的效率


*** ENAS

1. 作者认为训练 NAS 网络的瓶颈在于使得模型收敛，但是却仅仅计算了测试正确率然后丢掉了训练的权重。
1. 最近的研究表明，训练相似任务的网络会得到相似的权重，所以迁移学习可以在很短的时间内收敛。
1. ENAS 强制模型使用上次训练得到权重，而不是从头开始训练。本质上就是在新的模型上使用迁移学习。

ENAS 可以仅仅使用 1 块 1080Ti 耗费半天就可以训练完成。


** AutoML

Many people are calling AutoML the new way of doing deep learning, a change in the entire system. Instead of designing
complex deep networks, we’ll just run a preset NAS algorithm.


** 实践

1. google 的 Cloud AutoML 可以只需要上传数据集，便可以得到需要的网络
1. [[https://github.com/keras-team/autokeras][AutoKeras]] 实现了 ENAS 算法


** 预言

1. search space is quite limited. 而且都是手工设计的 building blocks . <Exploring Randomly Wired Neural Networks for
   Image Recognition> 研究的就是这个


** 参考

1. [[https://towardsdatascience.com/everything-you-need-to-know-about-automl-and-neural-architecture-search-8db1863682bf][Everything you need to know about AutoML and Neural Architecture Search]]
