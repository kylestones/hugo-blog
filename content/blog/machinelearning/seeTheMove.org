#+TITLE:          见招拆招
#+AUTHOR:         Kyle Three Stones
#+DATE:           <2018-08-23 Thu 07:19>
#+EMAIL:          kyleemail@163.com
#+OPTIONS:        H:3 num:t toc:nil \n:nil @:t ::t |:t ^:t f:t tex:t
#+TAGS:           机器学习, 深度学习
#+CATEGORIES:     深度学习


机器学习并不是若干算法的堆积，熟练掌握了“十大算法”或“二十大算法”并不能让一切问题迎刃而解。所以不能将目光仅聚焦在具体算法
的推导和编程实现上。基本算法仅能呈现典型“套路”，而现实世界任务千变万化，以有限的套路应对无限的变化，焉有不败！所以务必掌
握算法背后的思想脉络，面对现实问题时，根据任务特点对现有套路进行改造融通。无论科研创新还是应用实践，皆以此为登堂入室之始。
--- 周志华 <机器学习>

还有张三丰传授太极剑法给张无忌时，张无忌忘记了剑法具体的招式，仅记住了太极剑法的指导思想，从而根据敌人的招式使用相应的制
敌之策，达到见招拆招的目的。

Easy to learn. Hard to master.

** YOLO

下面举 YOLO 算法中的几个的例子

1. 作者通过均方无法来计算预测的 binding boxes 和 ground truth 之间的误差，由于 loss function 中还包含分类错误的误差。而
   由于大多数的 grid cell 都没有目标，所以不应该让有目标和没有目标的 grid cell 产生相同权重的误差，所以作者让目标位置误
   差的权重 \(\lambda_{coord} = 5\) ，让没有目标的分类误差权重 \(\lambda_{noobj} = 0.5\) ，从而来平衡由于数量悬殊导致的
   问题。
2. 使用均方误差计算，size 比较大的目标相比于 size 比较小的目标产生更大的误差。所以作者使用开方之后的宽度和高度值相减然后
   求平方。
3. 作者使用 224x224 的图像在 ImageNet 上使用分类网络对检测网络进行预训练，同时作者想让检测网络输入的分辨率为 448x448 。
   由于需要同时改变输入的尺寸以及网络的任务，作者先使用 448x448 的ImageNet 对网络进行 fine-tune，然后在使用检测误差进行
   调优，以达到更好的效果。
4. 作者想要使用 Anchor Boxes ，但是 R-CNN 一般都是人为设定其大小，这个是目标的先验，如果能有更好的先验，那么应该会有更好
   的检测结果，所以作者使用 k-means 聚类方法来求取 Anchor Boxes 先验的大小。
5. k-means 算法一般使用欧式距离度量误差，而此处，作者真实关心的是两者的 IOU ，所以作者用 1 - IOU 作为损失函数。

*可以发现作者始终在依据自己的实际需求，对算法进行了一些改进，而不是直接生搬硬套* 。


** Debug - Diagnostic

吴恩达老师也非常强调运用自己的聪明智慧去设计诊断方法。自己思考，自己想测试方法，去发现问题到底出现在哪里，而不要盲目的去
修改测试，白白浪费更多的时间。 *比如一定要找到是算法的收敛性问题还是目标函数选择有问题？很多人在 \(J(\theta)\) 有问题的
时候，却始终在不断增加迭代次数。*

花费在诊断上的时间通常在 1/3 - 1/2 之间，但这些时间是值得的。Error analysis and diagnostic also give insight into the
problem.

吴恩达老师讲解了一些调试的方法，但是他说 Don't think of these analyses as sort of formulas that are constants. I mean
feel free to invent your own as well. 

还有不要在没有找到真正影响性能的地方就过早优化代码或者模型的某个组件。

先不要去研究那些高深的理论，时刻保持这样的想法：我真的需要研究 VC 维、三维建模、... 吗？他们可能对应用的效果非常有限，只
有亲自确认其与结果有关联，再去研究。

Debug 的时候一定要先考虑简单的情形，此时更容易思考，而且更容易发现问题。如果直接分析复杂的情况可能会让你手忙脚乱，陷入在
各种琐碎的问题中，而无法找到病因。


*** Bias - Variance

当最终测试结果发现模型误差太高时有很重种方法可以改进，但需要找到问题的真正原因，否则只是在浪费时间。

1. 如果训练误差很小，但测试误差很大，说明模型对训练样本过拟合了。此时可以增大训练样本的个数，或者添加正则化项来防止过拟
   合。
2. 如果模型的训练误差就很大，那么可能算法没有很好的收敛，可以使用更好的优化方法或者增加迭代次数

训练模型自动过滤垃圾邮件，最终测试结果发现判定垃圾邮件的错误率为 2% ，而判定非垃圾邮件的错误率也是 2% (将正常邮件中 2%
比例的邮件判定为垃圾邮件)。显然拒绝 2% 的正常邮件是不可容忍的，此时说明目标函数选取有问题，我们更关心非垃圾邮件的错误率，
所以在目标函数中增大该项的权重，以惩罚错误分类。


*** Diagnostic

吴恩达使用强化学习来控制直升机的例子

1. 建立一个直升机的模拟器，用于模拟直升机飞行
2. 选择一个损失函数，如 \( J(\theta) = || X - X_{disposed} ||^2 \) ，X 是直升机的位置
3. 运行强化学习算法来使 \(J(\theta)\) 最小

但最终飞行效果比人工飞行的效果要差很多。。。

假设

1. 直升机的模拟器是正确的
2. RL 算法能正确最小化 \(J(\theta)\) 
3. 最小化 \(J(\theta)\) 能够正确控制直升机飞行

诊断

1. 使用 \(\theta_{RL}\) 在模拟器中飞行，如果可以飞行的很好，说明模拟器建模有问题，未能真实反应直升机模型
2. 让人操作直升机，比较 \(J(\theta_{human})\) 和  \(J(\theta_{RL})\) 的大小，若 \(J(\theta_{human}) < J(\theta_{RL})\)
   ，说明 RL 算法没有使 \(J(\theta)\) 最小
3. 若 \(J(\theta_{human}) > J(\theta_{RL}) \) ，说明目标函数有问题。

一个非常有价值的事是对问题诊断形成你个人的直观理解。


*** Error analysis

很多机器学习问题是由很多独立的组件通过流水线的方式组成在一起的，分析误差源自哪个组件：可以逐渐用基准组件代替每个组件，找
到准确率提升最多的地方。

choosing the right piece is critical.

而深度学习中很多都使用端到端的网络，分析方法变得不同。此时需要检测分析那些分类或者检测错误的目标，总结这些错误的规律，从
而针对性的进行修改网络结果或者调整训练样本。


