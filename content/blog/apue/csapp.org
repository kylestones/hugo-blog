#+TITLE:       Computer Systems - A Programmer's Perspective
#+AUTHOR:      kyle Three Stone
#+DATE:        <2018-05-24 Thu>
#+EMAIL:       kyleemail@163.com
#+OPTIONS:     H:3 num:t toc:t \n:nil @:t ::t |:t ^:t f:t TeX:t
#+TAGS:        csapp, Linux
#+CATEGORIES:  csapp


** 局部性

局部性良好的代码速度会大大提高

分为时间局部性和空间局部性；时间局部性表明一个变量在不远的将来会再次被访问；空间局部性表明一个变量周围的变量很快会被访问。

代码提升的关键在于充分利用高速缓存 cache (CPU 和主存读写速度之间的差距在不断增大）


** 程序的机器级表示

*汇编代码以及机器码都不包含任何变量名字以及类型信息* 。程序就仅仅是一些数字序列而已。

在代码中假如汇编的方法：
1. 函数使用汇编代码实现，然后链接的回收使用
1. 使用 GCC 提供的选项，直接在 C 函数中插入汇编代码


*** x86-64 16 个通用寄存器

+ Instruction pointer :: %rip
+ Stack pointer :: %rsp
+ Return value :: %rax
+ Arguments passed in registers :: %rdi, %rsi, %rdx, %rcx, %r8, %r9
+ Callee-saved :: %rbx, %r12, %r13, %r14, %rbp, %rsp
+ Caller-saved :: %rdi, %rsi, %rdx, %rcx, %r8, %r9, %rax, %r10, %r11

x86-64 惯例，操作 32 位寄存器，会将该寄存器的高 32 位设置为 0 。


** 栈

栈的地址向下增长，即每次压栈都会导致寄存器 %rsp 的值减小。大多数函数都需要栈帧（栈上的一段内存）来保存信息，栈帧的结构从
栈底到栈顶依次为 

1. 保存的 callee-saved 寄存器的值
1. 局部变量
1. 调用其他函数需要的 6 个参数寄存器以外的内存
1. 返回地址

程序使用栈完成函数调用，此时主要由寄存器 %rip 以及 %rsp 完成

1. callq 指令完成将 callq 的下一条指令地址压栈，并 jump 到被调函数的第一条指令
1. ret 指令从栈中弹出之前保存在栈上的地址，并 jump 到该地址

以上是栈固定的时候

动态数组需要不定大小的栈，此时需要寄存器 %rbp 辅助实现。

+ ret 指令等效于 :: popd %rip; jump %rip
+ leave 指令等效于 :: movq %rbp, %rsp; popd %rbp


** 堆

由 glic 负责维护，使用 sbrk 系统调用来申请内存，然后 glic 提供 malloc 和 free 接口供应用程序使用。


*** 实现自己的 malloc free 函数

要求：

+ Handling arbitrary request sequences :: malloc 和 free 可能是任意的顺序
+ Making immediate responses to requests :: 不可以缓存请求或者对请求重新排序，必须立即响应
+ Using only the heap :: 函数使用的结构体 (nonscalar data) 必须存储在 heap 中
+ Aligning blocks :: 8 字节对齐
+ Not modifying allocated blocks :: 不可以对已经分配的 blocks 进行修改

目标：

+ Maximizing throughput :: 每秒钟响应请求的次数
+ Maximizing memory utilization :: heap 峰值使用率（aggregate payload / total heap)

Implementation Issues

+ Free block origanization :: 怎样保存 free blocks ；隐士链表，显示链表
+ Placement :: 选择合适 free block 作为新申请的 block ； first fit, next fit, best fit
+ Splitting :: 是否以及怎样分割 block 中剩余的部分
+ Coalescing :: 怎样合并被释放的 block ； 考虑 previous 和 next 是否是 free 共分为四种情况

之前尝试写过几天，但是后来重装系统，换电脑等。 I lost my code. Restart !!!
终于在 2020 年国庆节，20201001-20201006 利用 6 天时间实现了分离空闲链表的 malloc-free 函数。
大概是 3 天时间看书，3 天时间写代码调试，使用 CMU2010 年的实验版本，网上基本上都是 2001 年的实验。

*** 小函数 

+ mm_ init 初始化，为分离空闲链表的入口申请空间，初始化序言块和结尾块，预先申请一定大小的空间
+ find_ entry_ in_ segregated_ list 根据 size 得到分离空闲链表的起始地址（使用了多个 if 判断，不优雅）
+ insert_ to_ segregated_ list 清空 allocated bit ,调用 find_ entry_ in_ segregated_ list 找到分离空闲链表的入口，遍历链表，按照 block 的size 从小到大排序
+ delete_ from_ segregated_ list 置位 allocated bit ，无需遍历链表，直接修改前驱的 succ 指针和后继的 pred 指针即可
+ coalesce 处理四种情况下的合并，根据需要调用 delete_ from_ segregated_ list 将 block 从空闲链表摘除，计算新 block 的起始地址和大小，设置块的头尾节点，然后调用 insert_ to_ segregated_ list 插入空闲链表
+ extent_ heap 确保对齐和最小块的大小，通过系统调用 sbrk 增加堆的大小，初始化该 block 和结尾块，最后调用 coalesce 插入空闲链表（前面块可能是 free 的）
+ find_ fit 先调用 find_ entry_ in_ segregated_ list 找到空闲链表的入口，然后使用双层循环，外循环遍历之后的空闲链表入口，内循环遍历单个空闲链表，直到找到满足要求的 block ，如果未找到，则调用 extent_ heap 扩展堆，并返回块地址
+ place 将该 block 从空闲链表摘除，如果剩余的 size 大于等于最小块的 size ，则将该 block 分割成两部分，剩余的 block 在加入分离空闲链表
+ malloc 计算调整需要的 block size ，调用 find_ fit 查找合适的 block ，调用 place 放置
+ free 立即合并：如果入参不为空，则调用 coalesce 清空 allocated bit ，合并后加入空闲链表

调试函数
 + mm_ print_ heap 从序言块开始，遍历所有的 block ，打印其 header 和 footer ；遍历所有的空闲链表，打印其 header 和 footer
+ mm_ checkheap 检查序言块和结尾块，block 地址对齐，堆边界检查，header 和 footer 是否匹配，是否存在连续的 free block ；空闲链表 pred/succ 双向指针连续，空闲链表地址未越界，各个 free block size 满足空闲链表范围，通过 header footer 计算得到的空闲链表数量等于通过 pred 和 succ 计算得到的空闲链表数量


** 虚拟内存

+ virtual memory :: 是相对于物理内存（就是主存或者称为内存）而言的，其并不是由实际存在的内存芯片提供的存储空间。而是操作系统为每个进程虚拟出来的地址空间。

操作系统为每个进程提供 4GB(32bit) 或 256TB(64bit) 的虚拟地址空间，这里的地址空间就是虚拟内存。也就是一个进程里面的变量的地址、函数的地址、堆、栈、共享内存等
都是虚拟地址空间中的一个虚拟地址。进程在执行的过程中，CPU 访问一个虚拟地址 virtual address (VA)，会经过转换生产物理地址 physics address (PA)，然后再由这个 PA 来
访问实际存储数据的物理内存。


*** 虚拟地址到物理地址的转化

VA 到 PA 的转换主要涉及到 MMU 和 page table （页表）。
+ MMU  :: 执行 VA 到对应的 PA 转换的动作；由 CPU 硬件实现来加快速度
+ 页表 :: 提供转换规则（就是 VA 和 PA 的对应关系）；由内核负责维护更新

MMU 就是查询页表，将 VA 作为索引来查找 PA 。页表是 page table entry 组成的一个大数组。每个 page table entry 的地址就是 VA ，存储的内容就是 PA 。
VA 也可以看做是 PA 的缓存（内存层次结构），将 VA 和 PA 都分成相同大小的块，在虚拟存储器中称为页，Linux 中页大小默认为 4K 。
CPU 产生一个虚拟地址的时候，发送给 MMU 单元，MMU 单元搜索 page table ，以 VA 为索引，找到对应的 PA ，然后从对应的物理内存中取出数据后返还给 CPU 。

由于程序的局部性 locality ，程序往往在一个娇小的活动页面 active page 集合上工作，这个集合称为工作集 working set 或者常驻集 resident set 。
对这个工作集的应用不会产生额外的磁盘流量。如果工作集的大小超出了物理存储器的大小，那么程序将处理颠簸 thrashing 状态，速度会及其缓慢。 

+ 页命中 :: 如果页表中保存有需要的 VA 所对应的 PA ，说明相应的数据已经缓存在物理内存中，也称为页命中
+ 缺页 :: 页表中 VA 所对应的 PA 是无效的，说明需要的数据没有缓存在主存中，需要从磁盘读取，也称为缺页。从硬盘读取必然造成性能的下降，也称为缺页损失。内核有相应的页面调度算法（按需调度等）来更新维护页表。
+ 页表 :: 操作系统为每个进程维护独立的维护页表，因为每个进程都有一个独立的虚拟地址空间。页表也是数据，保存在磁盘。
+ TLB :: 为了加速对页表的访问，CPU 内置了 translation lookaside buffer 翻译后备缓冲区。使用虚拟内存后，CPU 读取一个数据需要访问两次，第一次读取页表，查询页表得到物理地址，然后再访问对应的物理地址处的数据，无疑会降低性能。TLB 处于 CPU  芯片内部，将常用的页表缓存起来，来加速页表的读取。使用虚拟地址访问
+ cache :: 这里指的是 CPU 的 L1 L2 L3 缓存。cache 由 CPU 负责缓存主存的数据，操作系统无法控制。使用物理地址访问。其实就可以理解成主存，只是速度更快。

*** 虚拟内存作用-优点

+ 作为缓存工具 :: 管理主存和磁盘之间的缓存
+ 作为存储器管理工具 :: 每个进程都使用相同的虚拟地址空间，简化链接、简化加载、简化共享、简化存储器分配
+ 作为存储器保存工具 :: 在 page table entry 中会保存该页的权限位 SUP READ WRITE ，如果指令违反响应的权限位，会导致段错误

*** 多级页表

在 32 位虚拟地址空间中，页大小为 4K ，每个 PTE 为 4 个字节，页表的大小为 2^32 / 2^12 * 4 = 4MB ，即使只使用很少一部分虚拟地址空间也是这样。
64 位的时候，页表大小 2^48 / 2^12 * 8 = 512GB ，这几乎是不现实的。为了压缩页表，常用的方法是使用层次结构的页表，即使用多级页表，
第一级页表表示一个较大的范围，每个条目指向一个第二级页表的起始地址，第二级页表的每个条目范围较第一级小，后续的页表类似。
而且，一个二级页表所有条目表示范围之和等于一个一级页表条目的范围，每级页表所有条目和其表示范围的乘积都是整个虚拟地址空间。
使用多级页表之后，只有第一级页表需要始终缓存，其他的页表根据需要创建。

VA 被分割成 VPN 虚拟页号 virtual page number 和 VPO  虚拟页偏移 virtual page offset ，多级页表时，VPN 又被分割成 VPN1 VPN2 VPN3 …… 同时物理地址也被分割成 PPN 物理页号 physical page number 和 PPO 物理页偏移 physical page offset 。其中 VPO 和 PPO 大小相同。

Core-i7 采用四级页表层次结构， CR3 寄存器（属于进程上下文，每次进程上下文切换，CR3 都会被覆盖）指向第一级页表的起始位置，48 位 VA 分成 36 位 VPN 和 12 位 VPO ，
36 位 VPN 由于使用四级页表，每级使用 9 位。VPN1 提供8个到 L1 PTE 的偏移量，这个 PTE 包含 L2 页表的基地址，VPN2 提供到 L2 PTE 的偏移量，以此类推。


*** 优化地址翻译

地址翻译包括：MMU 将 VA 翻译成 PA ；将 PA 传送到 L1 cache 两个步骤。硬件实现允许这两个步骤部分重叠。当 CPU 需要翻译一个虚拟地址的时候，它发送 VPN 到 MMU ，发送 VPO 到 L1 cache 。当 MMU 向 TLB 请求一个页表条目时， L1 cache 正忙着利用 VPO 查找相应的组，并读出这个组里的 8 个标记。当 MMU 从 TLB 得到 PPN 时，缓存已经准备好试着吧这个 PPN 与这 8 个标记中的一个进行匹配了。

VPO 和 PPO 是 12 位，L1 缓存是 8 路组相连，共 64 个组，块大小为 64 字节。



** 链接

** 存储器层次结构

中心思想：位于 k 层的更快更小的存储设备作为位于 k+1 层更大更慢的存储设备的缓存。

| 层次 | 存储器    |
|------+-----------|
| L0   | 寄存器    |
| L1   | L1:SRAM   |
| L2   | L2:SRAM   |
| L3   | L3:SRAM   |
| L4   | 主存:DRAM |
| L5   | 磁盘      |
| L6   | 网络      |

k+1 层存储被划分成连续的数据块 block 【大小一般固定】，每个块都有一个唯一的地址，k 层使用同样大小的块划分。第 k 层存储包含 k+1 层块的子集的一个拷贝。
不同层次之间的块大小可以不同。

+ 缓存管理 :: 负责块的划分，在不同层之间传递块，处理命中/不命中等。缓存管理可以由硬件/软件/两者结合来实现。


*** 高效缓存存储器结构

CPU 内部的 L1 L2 L3 高速缓存，包括 TLB ，都是高速缓存 cache ，存储结构都是相似的。使用 (S,E,B,m) 通用组织结构，共有 S=2^s 个高速缓存组 cache set ，
每个组包含 E 个高速缓存行 cache line ，每行由一个 B=2^b 字节的数据块 block 组成（每行只存储一个块），一个有效位 valid bit 指名这个行是否包含有意义的信息。

在高速缓存中地址被分为三个部分 t 位标记位 tag bit ，s 为组索引位 set index ，和 b 位块偏移位 block offset 位。
一个组中有几行就称为几路组相连，如 inter-i7 L1/L2 是 8 路组相连，L3 是 16 组相连，块大小都是 64 字节；TLB 是 4 路组相连，共 16 组。
查找时，先通过组索引找到对应的组，然后比对 tag 值和有效位，最后通过块偏移得到数据的位置。

+ 为什么用中间位做索引 :: 希望利用局部性，相邻地址缓存越多越好。使用中间位做索引，相邻的地址被映射到不同的块；如果使用高位做索引，相邻的地址会被映射到相同的块。
