<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>机器学习 | Org Mode</title><meta name=keywords content><meta name=description content="ExampleSite description"><meta name=author content="Me"><link rel=canonical href=https://kylestones.github.io/hugo-blog/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/hugo-blog/assets/css/stylesheet.abc7c82c3d415a6df50430738d1cbcc4c76fea558bc5a0c830d3babf78167a35.css integrity="sha256-q8fILD1BWm31BDBzjRy8xMdv6lWLxaDIMNO6v3gWejU=" rel="preload stylesheet" as=style><link rel=icon href=https://kylestones.github.io/hugo-blog/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://kylestones.github.io/hugo-blog/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://kylestones.github.io/hugo-blog/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://kylestones.github.io/hugo-blog/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://kylestones.github.io/hugo-blog/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://kylestones.github.io/hugo-blog/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/index.xml><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme: rgb(29, 30, 32);--entry: rgb(46, 46, 51);--primary: rgb(218, 218, 219);--secondary: rgb(155, 156, 157);--tertiary: rgb(65, 66, 68);--content: rgb(196, 196, 197);--hljs-bg: rgb(46, 46, 51);--code-bg: rgb(55, 56, 62);--border: rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');ga('create','UA-123-45','auto');ga('send','pageview');}</script><meta property="og:title" content="机器学习"><meta property="og:description" content="ExampleSite description"><meta property="og:type" content="website"><meta property="og:url" content="https://kylestones.github.io/hugo-blog/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><meta property="og:image" content="https://kylestones.github.io/hugo-blog/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="og:site_name" content="ExampleSite"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://kylestones.github.io/hugo-blog/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="机器学习"><meta name=twitter:description content="ExampleSite description"></head><body class=list id=top><script>if(localStorage.getItem("pref-theme")==="dark"){document.body.classList.add('dark');}else if(localStorage.getItem("pref-theme")==="light"){document.body.classList.remove('dark')}else if(window.matchMedia('(prefers-color-scheme: dark)').matches){document.body.classList.add('dark');}</script><header class=header><nav class=nav><div class=logo><a href=https://kylestones.github.io/hugo-blog accesskey=h title="Home (Alt + H)"><img src=https://kylestones.github.io/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://kylestones.github.io/hugo-blog/categories/ title=categories><span>categories</span></a></li><li><a href=https://kylestones.github.io/hugo-blog/tags/ title=tags><span>tags</span></a></li><li><a href=https://example.org title=example.org><span>example.org</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://kylestones.github.io/hugo-blog>Home</a></div><h1>机器学习</h1></header><article class="post-entry tag-entry"><header class=entry-header><h2>Deep Learning</h2></header><div class=entry-content><p>神经网络和深度学习 神经网络概论 结构化数据(structured data)：每个特征都有清晰、明确有意义的定义；比如房屋的面积，人的身高等 非结构化数据(unstructured data)：特征无法精确定义；比如图像的像素点，音频，文字 人类很擅长处理结构化的数据，但机器很不擅长。而归功于深度学习，使得机器在非结构化数据的处理有了明显的提高；但是现在比较挣 钱的仍然是让机器处理结构化数据，如广告投放、理解处理公司的海量数据并进行预测等。吴恩达希望设计的网络可以处理结构化数据也 可以处理非结构化的数据。 每个神经元类似一个乐高积木(Lego brick) ，将许多神经元堆叠在一起就形成了一个较大的神经网络。而且并不会人为决定每个神经元 的作用，而是由神经网络自己决定每个神经元的作用。如果给神经网络足够多的训练数据，其非常擅长计算从输入到输出的精确映射。神 经网络在监督学习中效果很好很强大。 神经网络有不同的种类，有用于处理图像的 CNN(Convolution Neural Network)、处理一维序列的 RNN(Recurrent Neural Network)、以 及自动驾驶中用于处理雷达数据的混合神经网络(Hybrid Neural Network)[对于复杂的问题，需要自行构建网络的架构；和机器学习中的 算法一样，针对具体的问题，需要去做具体的优化，而不是一成不变的使用基本的算法] scale 使得神经网络在最近流行起来，这里的 scale 并不单单指神经网络的规模，还包括数据的规模。当训练样本不是很大的时候，神 经网络与传统的机器学习算法之间的优劣并不明显，此时主要取决有人为设计算法的技巧和能力以及算法处理的细节，可能一个设计良好 的 SVM 算法结果要优于一个神经网络的效果；但是随着样本量不断变大，传统的机器学习算法的性能会在达到一定的性能之后效果变无 法继续提升，而神经网络此时的效果将明显领先于传统的算法[需要很大的样本，且网络的规模越大，性能越好]。数据、计算能力、算法 都促使了深度学习的发展；算法的主要改进都在加快算法的速度，比如使用 ReLU 函数替代 sigmoid 函数就大大加快了算法的训练速度， 因为 sigmoid 函数在自变量趋向于正负无穷大的时候，导数趋向于 0，而使用梯度下降法，梯度的减小将使得参数的变化变得缓慢，从 而学习将变得缓慢；而 ReLU 函数右侧的斜率始终为 1，由于斜率不会逐渐趋向于 0，使得算法训练速度大大提高（ReLu: rectified linear unit ，修正线性单元；修正指的是取不小于 0 的值）。速度的提升使得我们可以训练大型的网络或者在一定的时间内完成网络 的训练。而且训练神经网络的过程一般是 idea - code - experiment - idea 不断循环，迭代的更快使得验证自己的想法更加快速得到 验证，将有机会取验证更多的想法，从而更有可能找到合适的结果。 1989 年 Robert Hecht-Nielsen 证明了万能逼近定理：对于任何闭区间的一个连续函数都可以用一个隐含层的 BP 网络来逼近（完成任 意m 维到 n 维的映射）。虽然如此，但是若要模拟复杂的函数可能需要特别特别多的隐层神经元，因此现代网络总是加大网络的深度， 以让每一层的函数尽量简单，而整个网络完成复杂的映射。 神经网络基础 一张彩色图像像素点由 RGB 三个通道组成，作为神经网络的输入时，将三个矩阵都转换成向量并拼接起来组成一个列向量 \(x^{(i)} \in \mathbb{R}^{n_x}\)，列向量中先是红色通道的所有像素点，然后是绿色通道的所有像素点，最后是蓝色通道的所有像素点。m 个训 练样本 \(\{ (x^{(1)},y^{(1)}), (x^{(2)},y^{(2)}), \cdots, (x^{(i)},y^{(i)}) \}\) ；同时使用 \(X \in \mathbb{R}^{n_x \times m} \) 表示所有的训练样本\[X= \left[ \begin{array}{cccc} | & | & & | \\ x^{(1)} & x^{(2)} & \cdots & x^{(m)} \\ | & | & & | \end{array} \right] \] 相比于让每个样本按行向量堆叠，在神经网络中构建过程会简单很多。\(y^{(i)} \in \{0,1\}\)同 时将所有的标签组成一个行向量 \(Y \in \mathbb{R}^{1 \times m}\) \[ Y = [ y^{(1)}, y^{(2)}, \cdots, y^{(m)} ]\] 在Python 中使用 (n,m) = X....</p></div><footer class=entry-footer>22 min&nbsp;·&nbsp;4670 words&nbsp;·&nbsp;Kyle Three Stones</footer><a class=entry-link aria-label="post link to Deep Learning" href=https://kylestones.github.io/hugo-blog/blog/machinelearning/deeplearning/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>Machine Learning</h2></header><div class=entry-content><p>ML *机器学习* machine learning: Field of study that gives computers the ability to learn without being explicitly program. 机器学习并不是仅仅是若干算法的堆积，学会“十大算法”，熟练掌握具体算法算法的推导与编程实现，并不能让所有问题迎刃而解，因为 现实世界的问题千变万化。而应该像张无忌那样，忘记张三丰传授的太极剑法的具体招式，而只记住一些规则和套路，从而根据敌人的招 式去不断变化自己的招式，达到以不变应万变的效果。或者说用 Andrew Ng 的话，要成为一个 master carpenter （顶级木匠），可以 灵活使用工具来制造桌椅，只有手艺差的木匠才会抱怨工具不合适。因此必须把握算法背后的思想脉络，针对具体的任务特点，对现有套 路进行改造融通；要记住算法是 死 的，思想才是 活 的。 数据库提供数据管理技术，机器学习提供数据分析技术。 Supervised Learning 样本有标签的时候称为监督学习 Linear Regression 首先可以根据样本输入的维数来选择参数的个数（最终依据交叉验证的结果来选择模型和特征） \[ h_{\theta}(x) = \sum_{i=1}^{n} \theta_i x_i = \theta^{T}x \] 求取 \(\theta\) 的策略：在训练集上使得 \(h(x)\) 尽可能接近 y 。那么就涉及到距离的定义，距离通常定义为两者差的平方。因此 损失函数(cost function)定义为 \[ J(\theta) = \frac{1}{2} \sum_{i=1}^m (h_{\theta}(x^{(i)}) - y^{(i)})^2 \] 认为数据服从高斯分布 \(y|x;\theta \thicksim (\mu, \sigma^2)\) ，即其前置概率估计是高斯分布。 Last Mean Squares Algorithm 利用最小二乘法中的误差函数来描述损失函数；利用梯度下降法不断迭代来减小损失函数：先将参数初始化为某个值，然后不断迭代跟新 参数；跟新参数的规则：old value + 学习率 * 损失函数对该参数求偏导。 \begin{align} \theta_j & := \theta_j - \alpha \frac{\partial}{\partial \theta_j} J(\theta) \\ & := \theta_j + \alpha \sum_{i=1}^m (y^{(i)} - h_{\theta}(x^{(i)})) x_j^{(i)}, \quad for \ every \ j \\ & := \theta_j + \alpha (y^{(i)} - h_{\theta}(x^{(i)})) x_j^{(i)}, \quad for \ every \ j; \ outer \ for \ every \ i \\ \end{align} 最小二乘法(ordinary least squares)仅仅是描述损失函数的模型，本身不是一个最优解工具，可以求解线性以及非线性问题。最优化方 法有：梯度下降法；矩阵解法；牛顿法；坐标上升法； 判断收敛： 两次迭代，发现 \(\theta\) 变化不大 \(J(\theta)\) 基本不变 【常用】 最优化方法 梯度下降法 梯度下降法：结果与初值有关，且最终一定会结束在某个局部最小值。若维度非常高时，可能不存在局部最小值，可能只是鞍点（深度学 习）。数学上，某一函数在该点的方向导数沿着梯度方向取得最大值。 梯度下降法具体包括： batch gradient descent，批量梯度下降法：每次都需要计算所有样本的误差来更新参数 stochastic gradient descent / incremental gradient descent，随机梯度下降法：每次只需要计算一个样本的误差来更新参数。 可以较快的收敛，但参数结果可能始终在最优解周围徘徊，但在实际应用中可以满足 mini-batch：每次使用同样个数的一小批的样本来更新权重参数。 Newton's method 牛顿法用于查找一个函数的零点。假如希望找到使得 \(f(\theta) = 0\) 的 \(\theta\) 值。在 \(\theta\) 处，用函数 f 的切线来近 似 f ，找到切线的零值点；然后在切线的零值点开始继续用该点处的切线来近似表示函数，不断迭代直至参数满足要求。计算零值点时 可以利用直角三角形一个角的对边的长度除以临边的长度来得到该角的正切值，而正切值就是函数在该点的导数。 \begin{equation} \theta := \theta - \frac{f(\theta)}{f'(\theta)} \end{equation} 而求解似然函数的极值点，就是找到似然函数导数的零点 \begin{equation} \theta := \theta - \frac{\ell ' (\theta)}{\ell ''(\theta)} \\ \theta := \theta - H^{-1} _{\theta} \nabla \ell(\theta), \quad Newton-Raphson \end{equation} 牛顿法： 优点：初值不影响结果，一般选择 0 为初值；算法一般都会收敛且收敛速度比梯度下降法快很多，是二次收敛(quadratic conversions)[在解距离最优解足够近时，下一次误差为上一次误差的平方] 缺点：每次迭代都需要计算 Hessian 矩阵（n*n维）。如果特征维数较多，代价会比较大。 Maximum Likelihood Estimation - MLE 似然：参数的函数 概率：数据的概率 极大似然估计：选择参数 \(\theta\) 使得数据出现的可能性尽可能大。 让所有样本出现的概率最大，需要将每个样本的概率都乘起来，而连乘操作易造成数据下溢，因此通常采用对数似然(log-likelihood)， 将连乘转换成相加操作。 贝叶斯学派认为参数是未被观测的随机变量，其本身也可有分布。频率学派认为虽然参数未知，但确实客观存在的固定值。极大似然估计 源自频率学派。 Locally Weighted Linear Regression 只利用待预测样本周围的样本来预测结果。 \begin{align} w^{(i)} = exp \left( - \frac{(x^{(i)}-x)^2}{2\tau^2} \right) \\ \sum_i w^{(i)} (y^{(i)} - \theta^T x^{(i)})^2 \end{align} x 是待预测的值，样本距离 x 的距离 \( |x^{(i)} - x| \) 越近，权重越大；反之则越小。 \(\tau\) 称为波长参数，是一个超参，控制着权重随距离下降的速度。\(\tau\) 越小，权重衰减的钟形越窄；\(\tau\) 越大，权重 衰减的钟形越宽。而且权值函数的积分可能是正无穷而不是像高斯密度函数那样积分值为 1 局部加权线性回归并没有依据训练样本学习得到一些参数，而是在每次预测的时候都需要使用训练样本来决策。是一个非参数学习算法 (non-parametric)，非正式的可以理解为其参数随着训练样本的增加而增加。 Andrew Moore 的 KD tree 讲述了在训练集较多时，高效计算的方法。 Logistic Regression 逻辑斯蒂回归用于处理二分类问题。由于标记只有两个：0 和 1。所以当计算的结果超过 1 或者小于 0 将变得没有意义。因此选取一个 函数值从 0 平滑过度到 1 的函数用于将计算求得的结果重映射到区间[0-1]。这样的函数存在很多，但是逻辑斯蒂回归选择了 sigmoid function，也称为 logistic function。利用广义线性模型也会推导出此处选择 sigmoid 函数。 \begin{align} g(z) = \frac{1}{1+e^{-z}} \\ h_{\theta}(x) = g({\theta}^T x) = \frac{1}{1 + e^{-{\theta}^T x}} \end{align} 假设 \begin{align*} P(y=1|x;θ) & = hθ (x) P(y=0|x;θ) & = 1 - hθ (x) P(y|x;θ) & = (hθ (x))^y (1 - hθ (x))1-y \end{align*} 似然函数：损失函数没有选择成算法输出与标记误差的平方，是因为这样的损失函数是非凸的，会有很多局部最优解而无法找到全局最优 解。 \begin{align*} ℓ(θ) & = ln L(θ) & = ln ∏i=1^m p(y|x;θ) & = ln ∏i=1^m (hθ (x(i)))^{y(i)} (1 - hθ (x(i)))^{1-y(i)} & = ∑i=1^m y(i) ln h(x(i)) + (1-y(i))ln(1-h(x(i))) \end{align*} 目标函数对 \(\theta\) 的每个分量求偏导，且求解过程直接使用 sigmoid 函数的导数表达式可简化计算。最终得到参数的迭代表达式 \begin{align} \frac{\partial}{\partial \theta_j} \ell(\theta) & = (y-h_{\theta}(x))x_j \\ \theta_j & := \theta_j + \alpha \sum_{i=1}^m(y^{(i)} - h_{\theta}(x^{(i)})) x_j^{(i)} \\ \theta_j & := \theta_j + \alpha(y^{(i)} - h_{\theta}(x^{(i)})) x_j^{(i)} \end{align} sigmoid 函数的导数： \begin{equation} g'(z) = g(z) (1-g(z)) \end{equation} 认为数据服从伯努利分布 \(y|x;\theta \thicksim Bernoulli(\phi)\) ，即数据的前置概率估计是伯努利分布。 TP – 将正类预测为正类的个数；true positive FN – 将正类预测为负类的个数；false negative TN – 将负类预测为负类的个数；true negative FP – 将负类预测为正类的个数；false positive 准确率、召回率、以及两者的调和均值（准确率和召回率都高的时候也会高）： \begin{gather} P = \frac{ TP }{ TP + FP } \\ R = \frac{ TP }{ TP + FN } \\ \frac{2}{F_1} = \frac{1}{P} + \frac{1}{R} \\ F_1 = \frac{2TP}{2TP + FP + FN} \end{gather} Perception Learning Algorithm sigmoid 函数并没有直接输出样本的类别标记，而是根据输出再与 0....</p></div><footer class=entry-footer>25 min&nbsp;·&nbsp;5289 words&nbsp;·&nbsp;Kyle Three Stones</footer><a class=entry-link aria-label="post link to Machine Learning" href=https://kylestones.github.io/hugo-blog/blog/machinelearning/machine-learning/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>见招拆招</h2></header><div class=entry-content><p>机器学习并不是若干算法的堆积，熟练掌握了“十大算法”或“二十大算法”并不能让一切问题迎刃而解。所以不能将目光仅聚焦在具体算法 的推导和编程实现上。基本算法仅能呈现典型“套路”，而现实世界任务千变万化，以有限的套路应对无限的变化，焉有不败！所以务必掌 握算法背后的思想脉络，面对现实问题时，根据任务特点对现有套路进行改造融通。无论科研创新还是应用实践，皆以此为登堂入室之始。 — 周志华 &lt;机器学习> 还有张三丰传授太极剑法给张无忌时，张无忌忘记了剑法具体的招式，仅记住了太极剑法的指导思想，从而根据敌人的招式使用相应的制 敌之策，达到见招拆招的目的。 Easy to learn. Hard to master. YOLO 下面举 YOLO 算法中的几个的例子 作者通过均方无法来计算预测的 binding boxes 和 ground truth 之间的误差，由于 loss function 中还包含分类错误的误差。而 由于大多数的 grid cell 都没有目标，所以不应该让有目标和没有目标的 grid cell 产生相同权重的误差，所以作者让目标位置误 差的权重 \(\lambda_{coord} = 5\) ，让没有目标的分类误差权重 \(\lambda_{noobj} = 0.5\) ，从而来平衡由于数量悬殊导致的 问题。 使用均方误差计算，size 比较大的目标相比于 size 比较小的目标产生更大的误差。所以作者使用开方之后的宽度和高度值相减然后 求平方。 作者使用 224x224 的图像在 ImageNet 上使用分类网络对检测网络进行预训练，同时作者想让检测网络输入的分辨率为 448x448 。 由于需要同时改变输入的尺寸以及网络的任务，作者先使用 448x448 的ImageNet 对网络进行 fine-tune，然后在使用检测误差进行 调优，以达到更好的效果。 作者想要使用 Anchor Boxes ，但是 R-CNN 一般都是人为设定其大小，这个是目标的先验，如果能有更好的先验，那么应该会有更好 的检测结果，所以作者使用 k-means 聚类方法来求取 Anchor Boxes 先验的大小。 k-means 算法一般使用欧式距离度量误差，而此处，作者真实关心的是两者的 IOU ，所以作者用 1 - IOU 作为损失函数。 可以发现作者始终在依据自己的实际需求，对算法进行了一些改进，而不是直接生搬硬套 。 Debug - Diagnostic 吴恩达老师也非常强调运用自己的聪明智慧去设计诊断方法。自己思考，自己想测试方法，去发现问题到底出现在哪里，而不要盲目的去 修改测试，白白浪费更多的时间。 比如一定要找到是算法的收敛性问题还是目标函数选择有问题？很多人在 \(J(\theta)\) 有问题的 时候，却始终在不断增加迭代次数。 花费在诊断上的时间通常在 1/3 - 1/2 之间，但这些时间是值得的。Error analysis and diagnostic also give insight into the problem....</p></div><footer class=entry-footer>2 min&nbsp;·&nbsp;220 words&nbsp;·&nbsp;Kyle Three Stones</footer><a class=entry-link aria-label="post link to 见招拆招" href=https://kylestones.github.io/hugo-blog/blog/machinelearning/seethemove/></a></article></main><footer class=footer><span>&copy; 2022 <a href=https://kylestones.github.io/hugo-blog>Org Mode</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z" /></svg></a><script>let menu=document.getElementById('menu')
if(menu){menu.scrollLeft=localStorage.getItem("menu-scroll-position");menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft);}}
document.querySelectorAll('a[href^="#"]').forEach(anchor=>{anchor.addEventListener("click",function(e){e.preventDefault();var id=this.getAttribute("href").substr(1);if(!window.matchMedia('(prefers-reduced-motion: reduce)').matches){document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({behavior:"smooth"});}else{document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();}
if(id==="top"){history.replaceState(null,null," ");}else{history.pushState(null,null,`#${id}`);}});});</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){if(document.body.scrollTop>800||document.documentElement.scrollTop>800){mybutton.style.visibility="visible";mybutton.style.opacity="1";}else{mybutton.style.visibility="hidden";mybutton.style.opacity="0";}};</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{if(document.body.className.includes("dark")){document.body.classList.remove('dark');localStorage.setItem("pref-theme",'light');}else{document.body.classList.add('dark');localStorage.setItem("pref-theme",'dark');}})</script></body></html>