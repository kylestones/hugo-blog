<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>cuda, | Org Mode</title><meta name=keywords content><meta name=description content="ExampleSite description"><meta name=author content="Me"><link rel=canonical href=https://kylestones.github.io/hugo-blog/tags/cuda/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/hugo-blog/assets/css/stylesheet.abc7c82c3d415a6df50430738d1cbcc4c76fea558bc5a0c830d3babf78167a35.css integrity="sha256-q8fILD1BWm31BDBzjRy8xMdv6lWLxaDIMNO6v3gWejU=" rel="preload stylesheet" as=style><link rel=icon href=https://kylestones.github.io/hugo-blog/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://kylestones.github.io/hugo-blog/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://kylestones.github.io/hugo-blog/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://kylestones.github.io/hugo-blog/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://kylestones.github.io/hugo-blog/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://kylestones.github.io/hugo-blog/tags/cuda/index.xml><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme: rgb(29, 30, 32);--entry: rgb(46, 46, 51);--primary: rgb(218, 218, 219);--secondary: rgb(155, 156, 157);--tertiary: rgb(65, 66, 68);--content: rgb(196, 196, 197);--hljs-bg: rgb(46, 46, 51);--code-bg: rgb(55, 56, 62);--border: rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');ga('create','UA-123-45','auto');ga('send','pageview');}</script><meta property="og:title" content="cuda,"><meta property="og:description" content="ExampleSite description"><meta property="og:type" content="website"><meta property="og:url" content="https://kylestones.github.io/hugo-blog/tags/cuda/"><meta property="og:image" content="https://kylestones.github.io/hugo-blog/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="og:site_name" content="ExampleSite"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://kylestones.github.io/hugo-blog/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="cuda,"><meta name=twitter:description content="ExampleSite description"></head><body class=list id=top><script>if(localStorage.getItem("pref-theme")==="dark"){document.body.classList.add('dark');}else if(localStorage.getItem("pref-theme")==="light"){document.body.classList.remove('dark')}else if(window.matchMedia('(prefers-color-scheme: dark)').matches){document.body.classList.add('dark');}</script><header class=header><nav class=nav><div class=logo><a href=https://kylestones.github.io/hugo-blog accesskey=h title="Home (Alt + H)"><img src=https://kylestones.github.io/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://kylestones.github.io/hugo-blog/categories/ title=categories><span>categories</span></a></li><li><a href=https://kylestones.github.io/hugo-blog/tags/ title=tags><span>tags</span></a></li><li><a href=https://example.org title=example.org><span>example.org</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://kylestones.github.io/hugo-blog>Home</a></div><h1>cuda,</h1></header><article class="post-entry tag-entry"><header class=entry-header><h2>cuda 编程基础</h2></header><div class=entry-content><p>学习周斌老师的《NVIDIA CUDA 初级教程视频》笔记 重看 CPU CPU 芯片中大量的晶体管用于 cache3 ，可以看到芯片中很大一部分面积都是 cache3 。主要由于 CPU 始终在大量的移动数据，将硬盘 中的数据移动到内存，将内存中的数据缓存到 cache ，将 cache 中的数据移动到寄存器，将某个寄存器移动到另一个寄存器，还有反向 的操作，将数据再写回硬盘，这些都是在大量的移动数据。CPU 主要是在为串行做优化，为了高速的数据移动，设计了内存管理单元、占 用很大芯片面积的 cache3 （或许是可以称 CPU 为吞吐机的原因），为了快速执行命令设计了各种分支预测、流水线、乱序执行等等。 整体架构 CPU 可以分成 数据通道 和 控制逻辑 两个部分。 Fetch 取址 -> Decode 译码 -> Execute 执行 -> Memory 访存 -> Writeback 写回 Pipeline 流水线是指令级并行 ILP 。可以极大的减小时钟周期，但同时也可能存在延迟（啥？），会增大芯片面积，指令流前后有关系时，无法 很好的利用流水线。流水线的长度称为级，并不是越大越好，通常在 14-20 级，不公开，涉及到芯片设计的商业秘密。 Bypassing 不等待前一条指令的所有流水线执行完成，只需要得到前一条指令结果的某一个数据，直接通过一个特殊的通道传递。 Branches 分支预测 Branch Prediction ，猜测下一条指令 ，基于过去分支记录，通常准确率大于 90% 分支断定 Branch Predication ，不使用分支预测，同时执行所有的分支。可减小面积、减小错误预测 IPC instructions per cycle ；超标量 superscalar ，增加流水线的宽度， N 条流水线。从而提高 IPC 指令调度 Read-After-Write - RAW Write-After-Read - WAR Write-After-Write - WAW 寄存器重命名来改善 Out-of-Order OoO 乱序执行，重排指令，获得最大的吞吐率。可以重排缓冲区或发射队列/调度器 存储器层次架构 寄存器 - L1 - L2 - L3 - 主存 - 硬盘 硬件管理 L1 , L2, L3 软件管理 主存 , 硬盘 缓存： 将数据放在尽可能接近的位置；利用时间/空间的临近性。 分区 Banking ，避免多端口 一致性 coherency 控制器 Memory Controller ，多个通道，增加带宽 编址方式 Shared Memory Distributed Memory Hybrid Distributed-shared Memory CPU 内部并行性 指令级并行 Instruction-Level extraction 超标量、乱序执行 数据并行 Data-Level Parallelism 矢量计算，单指令多数据 Single Instruction Multiple Data (SIMD) ; 执行单元 ALU 很宽， 寄存器很宽 线程级并行 Thread-Level Parallelism 同步多线程 Simultaneous Multithreading SMT ，多核 Multicore Multicore 真多核 除最后一级缓存外，不共享其他资源； 假多核 可能只是多个 ALU 锁存 多个线程读写同一款数据：加锁； 谁的数据是正确的 ： 缓存一致性协议 Cohernce 什么样的数据是正确的 Consistency ： 存储器同一性模型 Powerwall 由于能量墙的限制，导致摩尔定律无法保持。 新摩尔定律：多核、单核性能并不会大幅度提升，频率也基本不会有大的提升； 处理器的存储器带宽无法满足处理能力的提升。 Flynn 矩阵 SISD SIMD MISD NIND 名词不解释 Task 任务 Parallel Task 并行任务 Serial Execution 串行执行 Parallel Execution Shared Memory 共享存储 Distributed Memory 分布式存储 Communication 通信 Synchronization 同步 –> 破坏了独立性、并行性 Granularity 粒度 –> 任务划分的粒度 Observed Speedup –> 加速比 Parallel Overhead 并行开销 –> 通信、同步 Scalability 可扩展性 –> GPU 从 4 核到 400 核时，性能上的提升 并行编程模型 共享存储模型 shared memory model 线程模型 threads model 消息传递模型 message passing model 数据并行模型 Data Parallel Model –> 对数据切分 OpenMP , MPI , SPMD , MPMD Amdahl's Law 程序可能的加速比取决于可以被并行化的部分： speedup = 1/(1-p) 设计并行处理程序和系统 GPU 设计思路 去掉复杂的分支预测、乱序执行、内存管理等单元 设计加入多个核（多个 SM） 在一个核内增加 ALU 的宽度；即一个核内有多个 ALU ，ALU 被分成多个组，每个组内的 ALU 共享管理调度单元（指令流） 提供较大的上下文存储空间（pool of context storage），使得大量独立片元切换来掩藏延迟。每个 SM 上可以驻扎远多于 SP 个数 的线程 最终设计结果：一个 GPU 有多个 Streaming Multi-processor [SM] ，每个 SM 内有多个 Streaming Processor [SP] ，也就是 cuda core ，是最小的计算单元 ALU 。每个 SM 内的 cuda core 被分成多个组，有多个调用单元用于调度，一个调度单元同一时间可以调度 一个组，使得一个组内所有线程执行相同的指令，但读取不同的数据。同时一个 SM 内有一定数量的寄存器、共享存储空间、上下文存储 空间，动态分配给需要的单元。 具体编程时，并不需要关心具体的硬件结构， cuda 将线程设计了三级逻辑抽象： grid - block - thread 。并不与硬件结构一一对应。 一个 Grid 内，每个 Block 的线程数是一样的 Block 内每个线程可以 synchronize 同步； Block 内每个线程都可以访问 shared memory ； 每个 Block 内最多的线程数有一定的限制（不同的芯片会不一样）； 一个 Block 内的所有线程必须位于同一个 SM 中 ； Block 之间彼此相互独立执行，以任意顺序、任意调度；在运行期确定在哪个 SM 上调度，可扩展 GPU 适用于密集计算，高度并行的计算；其片上晶体管主要用于执行计算，而不是缓存数据或控制指令流。 GPU 带宽是非常宝贵的资源，应该尽量减少带宽请求次数，重复数据尽量只取一次。让 GPU 多做运算。GPU 显存很大，相对内存来说， 带宽也很大，但在片外（不再 GPU 芯片内，在显卡的板子上），但芯片内部局部存储较小，缓存较小。 # CPU GPU 协同方式；好难对齐呀！！！ 主存 显存 DRAM GDRAM | | CPU GPU | | I/O I/O PCIE SSE 显示向量运算指令；但 SIMD 处理并不总是需要显示 SIMD 指令，NVIDIA GPU 标量指令，但硬件进行矢量化，是 SIMT （单指令多 任务） GPU 架构决定，编写 GPU 代码的时候需要注意 尽量少用递归，至少不鼓励使用递归，尤其是很深层次的递归 不要使用静态变量 少用 malloc 函数，因为成千上万个线程都执行 malloc ，可能导致显存很快用尽，同时也会影响性能（猜测） 小心通过指针实现函数调用（注意区分设备侧和主机侧地址） GPU 内存模型 寄存器 片上，快速，可读写；线程专用。每个 SM 上有一定数量的寄存器，如 G80 ，每个 SM 有 8K 个寄存器 Local Memory 在片外的 Global Memory 中，每个线程私有。可存储稍微大一些的数据，一般用于存储自动变量数组，通过常量索 引访问；新的 GPU 有 cache Shared Memory 片上，全速随机访问，可读写； block 内共享。和 cache 在同一个层次，可理解为用户可编程的 cache 。每个 SM 内有固定大小的共享存储器，如 G80 中，一个 SM 有 16 KB shared memory ；需要注意 bank conflict Global Memory 片外，长延时（100 个时钟周期），可读写，随机访问性能差；带宽较大 300GB/s ，有 cache ；Host 可读写 Constant Memory 在 Global 中特定位置，即固定的地址，短延迟、高带宽、所有线程只读，容量较小，cache ；Host 可读写 存储器 编程声明 作用域 生命期 register 编译器管理，必须是单独的自动变量而不能是数组 thread kernel local 编译器管理，自动变量数组 thread kernel shared _ shared_ int sharedVar block kernel global _ device_ int globalVar grid application constant _ constant_ int constantVar grid application 线程调度 cuda 通过分级管理线程 Grid - Block - warp - Thread 。 逻辑 Block 可以想象对应硬件的 SM 。 warp 是 Block 内线程编号连续的 32 个线程， 是线程调度的最小单元 。warp 运行在一个 SM 中，threadIdx 值连续，硬件设计上 保证 warp 内的每个线程同步。 特征： 在硬件上，warp 的调度是 0 开销的（所有 warp 的上下文已经存储在硬件中） 同一时间，一个 SM 上只有一个 warp 在执行（不是一个 SM 上有多个调度器吗？多个调度器应该是可以同时执行多个 warp 的呀？ TODO） warp 内所有线程始终执行相同的指令 divergent warp 由于没有为每个线程设计一个调度器（会占用额外的芯片面积），一个 warp 共享一个调度器，所以所有的线程必 须执行相同的命令。如果有条件分支，那么 warp 内的所有线程都会执行所有的分支，只是线程在不需要的分支时 候不操作任何寄存器。warp 内分支发散 GPU 做了一些优化，不太不要重点关注。但需要考虑好的算法数据分割， 使得warp 能尽早完工，释放资源，从而更好的利用资源，如并行规约 Parallel Reduction 的一个简单情况，求 一个数组的和，算法每次执行两个数的相加，如果始终让相邻的两个数相加，那么 warp 将无法很好的被利用，修 改成让两个相差数组长度一半索引的两个数相加，之后的 warp 就可以较早的被释放。 问： 每个 warp 有 32 个线程，但每个 SM 中只有 8 个 SP ，这时候如何调度呢？ 答： 将 warp 分成四组，第一个时钟周期前 8 个线程执行一条命令，第二个时钟周期，随后的 8 个线程执行相同的命令，直到第四个 时钟周期，所有 32 个线程都执行完某一条命令，然后再执行下一条命令。即一条指令分成四次调度才能执行完成。当然这是很老的 GPU 才有的现象，现代 GPU 一个 SM 内 SP 的个数很多，不再需要分多次才能执行完一个 warp 。不过这种逻辑思想是一样的。 架构 SM 中 SP 的数量 开普勒 192 mashival 128 Fermi 32 问： 假设一个 kernel 包含 1 次 global memory 的读操作，需要 200 个 cycles ，和 4 次独立的 multiples/add 操作，需要多少 warp 才能隐藏内存延迟？ 答： 4 次乘/加操作，每次乘/加需要 4 个 cycles ，共需要 16 个 cycles ； 200/16 并向上取整得到 13 个 warp 。 TODO！@#￥% 线程同步可能导致 死锁 ，需要注意逻辑正确性 # 下面代码将导致死锁 if (condition) { ....</p></div><footer class=entry-footer>5 min&nbsp;·&nbsp;1030 words&nbsp;·&nbsp;Kyle Three Stones</footer><a class=entry-link aria-label="post link to cuda 编程基础" href=https://kylestones.github.io/hugo-blog/blog/cuda/cuda-basic/></a></article></main><footer class=footer><span>&copy; 2022 <a href=https://kylestones.github.io/hugo-blog>Org Mode</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z" /></svg></a><script>let menu=document.getElementById('menu')
if(menu){menu.scrollLeft=localStorage.getItem("menu-scroll-position");menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft);}}
document.querySelectorAll('a[href^="#"]').forEach(anchor=>{anchor.addEventListener("click",function(e){e.preventDefault();var id=this.getAttribute("href").substr(1);if(!window.matchMedia('(prefers-reduced-motion: reduce)').matches){document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({behavior:"smooth"});}else{document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();}
if(id==="top"){history.replaceState(null,null," ");}else{history.pushState(null,null,`#${id}`);}});});</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){if(document.body.scrollTop>800||document.documentElement.scrollTop>800){mybutton.style.visibility="visible";mybutton.style.opacity="1";}else{mybutton.style.visibility="hidden";mybutton.style.opacity="0";}};</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{if(document.body.className.includes("dark")){document.body.classList.remove('dark');localStorage.setItem("pref-theme",'light');}else{document.body.classList.add('dark');localStorage.setItem("pref-theme",'dark');}})</script></body></html>