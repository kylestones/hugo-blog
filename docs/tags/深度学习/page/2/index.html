<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>深度学习 | Org Mode</title><meta name=keywords content><meta name=description content="ExampleSite description"><meta name=author content="Me"><link rel=canonical href=https://kylestones.github.io/hugo-blog/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/hugo-blog/assets/css/stylesheet.abc7c82c3d415a6df50430738d1cbcc4c76fea558bc5a0c830d3babf78167a35.css integrity="sha256-q8fILD1BWm31BDBzjRy8xMdv6lWLxaDIMNO6v3gWejU=" rel="preload stylesheet" as=style><link rel=icon href=https://kylestones.github.io/hugo-blog/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://kylestones.github.io/hugo-blog/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://kylestones.github.io/hugo-blog/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://kylestones.github.io/hugo-blog/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://kylestones.github.io/hugo-blog/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://kylestones.github.io/hugo-blog/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/index.xml><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme: rgb(29, 30, 32);--entry: rgb(46, 46, 51);--primary: rgb(218, 218, 219);--secondary: rgb(155, 156, 157);--tertiary: rgb(65, 66, 68);--content: rgb(196, 196, 197);--hljs-bg: rgb(46, 46, 51);--code-bg: rgb(55, 56, 62);--border: rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');ga('create','UA-123-45','auto');ga('send','pageview');}</script><meta property="og:title" content="深度学习"><meta property="og:description" content="ExampleSite description"><meta property="og:type" content="website"><meta property="og:url" content="https://kylestones.github.io/hugo-blog/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><meta property="og:image" content="https://kylestones.github.io/hugo-blog/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="og:site_name" content="ExampleSite"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://kylestones.github.io/hugo-blog/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="深度学习"><meta name=twitter:description content="ExampleSite description"></head><body class=list id=top><script>if(localStorage.getItem("pref-theme")==="dark"){document.body.classList.add('dark');}else if(localStorage.getItem("pref-theme")==="light"){document.body.classList.remove('dark')}else if(window.matchMedia('(prefers-color-scheme: dark)').matches){document.body.classList.add('dark');}</script><header class=header><nav class=nav><div class=logo><a href=https://kylestones.github.io/hugo-blog accesskey=h title="Home (Alt + H)"><img src=https://kylestones.github.io/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://kylestones.github.io/hugo-blog/categories/ title=categories><span>categories</span></a></li><li><a href=https://kylestones.github.io/hugo-blog/tags/ title=tags><span>tags</span></a></li><li><a href=https://example.org title=example.org><span>example.org</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://kylestones.github.io/hugo-blog>Home</a></div><h1>深度学习</h1></header><article class="post-entry tag-entry"><header class=entry-header><h2>fast.ai</h2></header><div class=entry-content><p>调参 分阶段使用多个学习速率 越接近输入的层，在 fine-tune 的时候，参数需要调节的越小，越靠近输出层，参数需要调节的越大。因此在 fine-tune 的时候，不同 的层最好使用不同的学习速率。例如 1-2 层使用 0.001 ，3-4 层使用 0.01 ，5-6 层使用 0.1 等等，越远离输出层，逐渐让学习速率 缩小 10 倍。[ Once the last layers are producing good results, we implement differential learning rates to alter the lower layers as well. The lower layers want to be altered less, so it is good practice to set each learning rate to be 10 times lower than the last....</p></div><footer class=entry-footer>4 min&nbsp;·&nbsp;670 words&nbsp;·&nbsp;Kyle Three Stones</footer><a class=entry-link aria-label="post link to fast.ai" href=https://kylestones.github.io/hugo-blog/blog/machinelearning/fast-ai/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>Faster R-CNN</h2></header><div class=entry-content><p>预处理 减去 RGB 像素的均值（无论训练还是测试统一使用训练样本集的均值） Rescale 在图像的长边不超过阈值的情况下，将短边 resize 到指定值 def img_rescale(img, targetSize=600, maxSize=1000): w = img.width h = img.height minDim = min(w,h) maxDim = max(w,h) scale = targetSize / minDim if scale * maxDim > maxSize: scale = maxSize / maxDim img = rescale(img, scale) return img 为什么要这样 rescale 呢？这样仅仅只能让多数的图像的短边统一长度，长边的长度可能各不相同；另外一些图像长边都是最大值，但 是短边各不相同。这样做有什么意义呢？保持图像的横纵比？但是图像大小不一样，要怎样去训练呢？ RoI Pooling RPN 生成的 RoI 由 (r,c,h,w) 表示，其中 (r,c) 是左上角的坐标，(h,w) 是高和宽。 RoI max pooling works by dividing the h*w RoI window into an H*W grid of sub-windows of approximate size h/H * w/W and then max-pooling the values in each sub-window into the corresponding output grid cell....</p></div><footer class=entry-footer>5 min&nbsp;·&nbsp;989 words&nbsp;·&nbsp;Kyle Three Stones</footer><a class=entry-link aria-label="post link to Faster R-CNN" href=https://kylestones.github.io/hugo-blog/blog/machinelearning/r-cnn/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>mAP</h2></header><div class=entry-content><p>词语解释 mAP 是 Mean Average Precision 的缩写，是检测算法的评价指标。这个名词中包含两个平均，其中 Mean 取的是不同类别的平均值， Average 取的是不同的召回率的平均值，当然计算的是正确率 Precision 的平均值。另外 coco 数据集还取了不同 IoU 阈值的平均。 另外想说一下，recall 这个单词被国内广泛翻译称召回率，大多数人根本无法从字面理解这个召回率到底是个什么鬼。而周志华老师在 其西瓜书中，将 recall 翻译成查全率，将 precision 翻译成查准率。一下子直观了很多。查准率表示模型查找到结果的准确率，就是 你说这些都是好瓜，但其中真正是好瓜的比例；查全率表示模型找到所有正样本的比例，就是说在所有好瓜中，你判别出来了多少。 计算方法 不同的数据集有不同的 mAP 计算方法。主要包括 PASCAL 07 、PASCAL 10、COCO 数据集的计算方法较常用。 PASCAL 数据集使用的都是固定的 IoU 阈值（默认为 0.5），就是只要预测的 box 和真实的 box 的 IoU 大于等于 0.5 ，就认为检测正 确（当然类别也必须正确）。所不同的是 PASCAL 07 只计算 11 个查准率 precision 的平均值，而 PASCAL 10 则要求所有的检测结果 都用于计算 AP 。 PASCAL 07 只计算查全率 recall 在 0....</p></div><footer class=entry-footer>1 min&nbsp;·&nbsp;191 words&nbsp;·&nbsp;Kyle Three Stones</footer><a class=entry-link aria-label="post link to mAP" href=https://kylestones.github.io/hugo-blog/blog/machinelearning/map/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>Mask R-CNN</h2></header><div class=entry-content><p>训练 train 输入 mini-batch 论文指出每个 GPU 上面跑 2 张图片，共 8 个 GPU ，所以 batch-size = 16 TODO ；每张图片上 sample 256 个 anchor 用于训练。 image spatial 图片大小 到底是用多大尺寸的图片训练网络的？ paper 中将图像的短边 resize 为 800 （测试的时候也会 resize 吗？）; 800*1024 ? 800*800 ? 1024*1024 ? 任意 size ? TODO anchor anchor 用于生产目标的最初候选区域 生成 anchor 的方法 anchor scale [32, 64, 128, 256, 512] anchor ratio [0....</p></div><footer class=entry-footer>4 min&nbsp;·&nbsp;788 words&nbsp;·&nbsp;Kyle Three Stones</footer><a class=entry-link aria-label="post link to Mask R-CNN" href=https://kylestones.github.io/hugo-blog/blog/machinelearning/maskrcnn/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>mxnet</h2></header><div class=entry-content><p>mxnet 常用包 from mxnet import gluon # 提供简单易用的 mxnet 接口 from mxnet import nd from mxnet import init # 用于权重参数初始化 from mxnet import autograd # 自动求导 from mxnet.gluon import nn # 用于构建网络结构 from mxnet.gluon import data as gdata from mxnet.gluon.data.vision import transforms # 用于变换数据 import sys import time 常用函数 transfroms.Compose 实现数据格式的转换，转换成 (height, width, channel) 格式，以及变成浮点数；这是 mxnet 要求的格式； 同时可以实现 argument gluon....</p></div><footer class=entry-footer>7 min&nbsp;·&nbsp;1490 words&nbsp;·&nbsp;Kyle Three Stones</footer><a class=entry-link aria-label="post link to mxnet" href=https://kylestones.github.io/hugo-blog/blog/machinelearning/gluon/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://kylestones.github.io/hugo-blog/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/>« Prev</a>
<a class=next href=https://kylestones.github.io/hugo-blog/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/page/3/>Next »</a></nav></footer></main><footer class=footer><span>&copy; 2022 <a href=https://kylestones.github.io/hugo-blog>Org Mode</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z" /></svg></a><script>let menu=document.getElementById('menu')
if(menu){menu.scrollLeft=localStorage.getItem("menu-scroll-position");menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft);}}
document.querySelectorAll('a[href^="#"]').forEach(anchor=>{anchor.addEventListener("click",function(e){e.preventDefault();var id=this.getAttribute("href").substr(1);if(!window.matchMedia('(prefers-reduced-motion: reduce)').matches){document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({behavior:"smooth"});}else{document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();}
if(id==="top"){history.replaceState(null,null," ");}else{history.pushState(null,null,`#${id}`);}});});</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){if(document.body.scrollTop>800||document.documentElement.scrollTop>800){mybutton.style.visibility="visible";mybutton.style.opacity="1";}else{mybutton.style.visibility="hidden";mybutton.style.opacity="0";}};</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{if(document.body.className.includes("dark")){document.body.classList.remove('dark');localStorage.setItem("pref-theme",'light');}else{document.body.classList.add('dark');localStorage.setItem("pref-theme",'dark');}})</script></body></html>