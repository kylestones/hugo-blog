<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>深度学习 | Org Mode</title><meta name=keywords content><meta name=description content="ExampleSite description"><meta name=author content="Me"><link rel=canonical href=https://kylestones.github.io/hugo-blog/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/hugo-blog/assets/css/stylesheet.abc7c82c3d415a6df50430738d1cbcc4c76fea558bc5a0c830d3babf78167a35.css integrity="sha256-q8fILD1BWm31BDBzjRy8xMdv6lWLxaDIMNO6v3gWejU=" rel="preload stylesheet" as=style><link rel=icon href=https://kylestones.github.io/hugo-blog/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://kylestones.github.io/hugo-blog/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://kylestones.github.io/hugo-blog/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://kylestones.github.io/hugo-blog/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://kylestones.github.io/hugo-blog/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://kylestones.github.io/hugo-blog/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/index.xml><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme: rgb(29, 30, 32);--entry: rgb(46, 46, 51);--primary: rgb(218, 218, 219);--secondary: rgb(155, 156, 157);--tertiary: rgb(65, 66, 68);--content: rgb(196, 196, 197);--hljs-bg: rgb(46, 46, 51);--code-bg: rgb(55, 56, 62);--border: rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');ga('create','UA-123-45','auto');ga('send','pageview');}</script><meta property="og:title" content="深度学习"><meta property="og:description" content="ExampleSite description"><meta property="og:type" content="website"><meta property="og:url" content="https://kylestones.github.io/hugo-blog/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><meta property="og:image" content="https://kylestones.github.io/hugo-blog/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="og:site_name" content="ExampleSite"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://kylestones.github.io/hugo-blog/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="深度学习"><meta name=twitter:description content="ExampleSite description"></head><body class=list id=top><script>if(localStorage.getItem("pref-theme")==="dark"){document.body.classList.add('dark');}else if(localStorage.getItem("pref-theme")==="light"){document.body.classList.remove('dark')}else if(window.matchMedia('(prefers-color-scheme: dark)').matches){document.body.classList.add('dark');}</script><header class=header><nav class=nav><div class=logo><a href=https://kylestones.github.io/hugo-blog accesskey=h title="Home (Alt + H)"><img src=https://kylestones.github.io/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://kylestones.github.io/hugo-blog/categories/ title=categories><span>categories</span></a></li><li><a href=https://kylestones.github.io/hugo-blog/tags/ title=tags><span>tags</span></a></li><li><a href=https://example.org title=example.org><span>example.org</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://kylestones.github.io/hugo-blog>Home</a></div><h1>深度学习</h1></header><article class="post-entry tag-entry"><header class=entry-header><h2>YOLO 实现细节</h2></header><div class=entry-content><p>之前写的乱七八糟，现在开始重构，主要针对 YOLOv3。真的是得亲自动手实现，才能真正了解一个算法。The best way to go about learning object detection is to implement the algorithms by yourself, from scratch. – Ayoosh Kathuria 主网络 主网络采用 Darknet53 ，网络为全卷积网络 FCN(Fully Convolutional Networks)，之前一直以为全卷积网络就是不包含全连接的网络， 现在才知道，全卷积网络连 Pooling 层都没有，Pooling 层使用步长为 2 的卷积代替，防止由于 Pooling 导致 low-level features 的丢失；分类之前使用 Global Average Pooling 。[Darknet53 中有全连接层呀，上面写错了] 卷积层 Darknet 的每个卷积层都是由 Conv-BN-LReLU 组成，是网络的最小重复单元。 def cbl_gen(channels, kernel_size, strides, padding): '''conv-BN-LeakyReLU cell''' cbl_unit = nn.HybridSequential() # 所有卷积后面都有 BN ，所以 bias 始终为 False cbl_unit....</p></div><footer class=entry-footer>11 min&nbsp;·&nbsp;2216 words&nbsp;·&nbsp;Kyle Three Stones</footer><a class=entry-link aria-label="post link to YOLO 实现细节" href=https://kylestones.github.io/hugo-blog/blog/machinelearning/yolo/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>乱想</h2></header><div class=entry-content><p>目标检测 loss 改进。类似人脸识别，通过改进 loss 来提高 map ； FocalLoss 也算是一种改进 微软的 Deformable-Convolutional 应该大有用处，现在功力没有很好的发挥出来 神经网络对细节很敏感，通过在图片上粘贴一些胶带就可以成功的误导网络。是不是说明网络没有很好的区分背景？或者说背景没有 达到随机的效果？将目标完全分割出来（没有背景）用于训练会怎样？感觉人类在观察事物的时候，第一步就是先对目标进行了分割 呀？ 网络参数剪枝 先训练一个大型的网络，然后裁剪成一个小一点的网络，其性能比直接训练的同等大小的网络效果要好很多。说明现在的网络训练方 法还是有很大的问题。 人类做梦是在进行无监督学习吗？ 神经网络的训练能否设计成监督训练和无监督训练相结合的方法？ AutoML 人工设计的特征远远没有网络自己提取的特征好，人工设计的网络结构也很有可能没有自己学习的结构效果好。每个人的大脑内的神经元 也应该是各不相同，我们只是被告知什么是猫、什么是鸟，而我们的神经元会自己学习怎样链接。 婚礼现场生成 一个人的一系列帧，可以插入视频某起始帧的某个地方 可以换脸，让自己喜欢的明星来参加自己的婚礼 边缘计算 软件硬化：高通 CMDA 、思科路由器、地平线 专业话，继续推动摩尔定律。由计算变化成 AI 低功耗 软件和硬件联合优化 特殊场景的特殊问题，一定要有场景。Google X 成立了 6-7 年，但只是一地鸡毛。 做东西一定要解决实际问题 。 对话系统：对话一定是要有目的，而不是仅仅为了对话。对话是要解决实际问题的。 亚马逊老总左贝斯：将理想和现实分开， 把握住十年中不变的东西。 最终由 big data 转变到 big computer 的 发展历程 余凯：历史都是先是 toC ，然后再是 toB 。 英伟达股票大幅增长，英伟达是 toC 。 创业 创业就是赌，如果是实实在在的放在桌子上东西，那根本不是创业，那是上班。 看长线，踏踏实实做下去，更可能钓大鱼。 看短期（最近 2-3 个月）和远期（目标），不用看半年或者 1-2 年，因为到时候，你的这段时间的思考都会废掉。</p></div><footer class=entry-footer>1 min&nbsp;·&nbsp;68 words&nbsp;·&nbsp;Kyle Three Stones</footer><a class=entry-link aria-label="post link to 乱想" href=https://kylestones.github.io/hugo-blog/blog/machinelearning/guess/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>人脸识别</h2></header><div class=entry-content><p>FaceNet A Unified Embedding for Face Recognition and Clustering 原来使用卷积神经网络来提取人脸的特征通常都是使用 softmax-loss 来训练网络，以期望网络的到的 embedding 足够好。本文作者直 接使用 embedding 的误差来训练网络，然后通过计算 embedding 的欧式距离来实现人脸验证。 triplet loss 每次使用三张图像，一个是 anchor ，另外两张中一张图像与 anchor 是同一个人，另一张是不同的人。 \begin{align*} L = ∑_i^N ≤ft [||f(x_i^a) - f(x_i^p)||_2^2 - ||f(x_i^a) - f(x_i^n)||_2^2 + α \right ]_+ \end{align*} Triplet Selection 为了较好的训练效果，挑选hard-positive 和 hard-negative 的人脸对，就是同一个人时选择两张差别最大的图像，不同人脸的时候， 挑选差别最小的两张图像。其中 \(\alpha\) 是 margin 。当然所有这些选择都是在一个 mini-batch 中，而不是整个训练样本中。 另外为了防止网络进入局部最优解或者训练崩溃（如 f(x) = 0），选择 semi-hard negative 样本，即满足 \[ ||f(x_i^a) - f(x_i^p)||_2^2 - ||f(x_i^a) - f(x_i^n)||_2^2 \] 论文中有 online 和 offline 两种方式来选择。选择方法较麻烦 center loss A Discriminative Feature Learning Approach for Deep Face Recognition 作者认为 Softmax 仅仅增加了类间离散度，并没有很好的减小类内离散度，所以作者对 softmaax-loss 进行了改造，增加了每一个样本 到中心点距离的惩罚项，强制让学习到的同一个人的 embedding 都簇拥到一起。Penalizes the distances between the deep features and their corresponding class centers....</p></div><footer class=entry-footer>2 min&nbsp;·&nbsp;291 words&nbsp;·&nbsp;Kyle Three Stones</footer><a class=entry-link aria-label="post link to 人脸识别" href=https://kylestones.github.io/hugo-blog/blog/machinelearning/facerecognition/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>卷积神经网络进化</h2></header><div class=entry-content><p>总体趋势：选取的函数越来越简单，手工设计的部分越来越少 CNN Yann Lecun 在 1998 的 LeNet 奠定了神经网络的基本架构 : CONV - POLING - FC 。 激活函数 在经典的神经网络以及 LeNet 中使用的激活函数都是 sigmoid 函数。sigmoid 函数是非线性函数，且在输入较大或者较小的时候斜率会 变得很小，不利于参数的学习。 从 AlexNet 开始，激活函数变成了 ReLU ，为分段线性，且 non-saturating，大大加快了网络的训练速度。同时为防止过拟合，提出了 Dropout 方法， Dropout 随机的使网络中的一些节点失活，使得节点不能过度依赖某一个输入，从而权重得以分散开来，另外使用随机 失活的网络，有预训练的效果，类似于先训练一个简单的网络，然后在没有失活的大型网络上 fine-tune 。虽然 AlexNet 网络与 LeNet 的架构基本相同，但由于其 ReLU 和 Dropout 等方法的使用，网络使用了 120 万张训练图片，从数据中学到了更本质的特征，将 cumulative match character (CMC) top5的正确率一下子提升了 10% ，成功掀起了深度学习的研究热潮。 何凯明大神在一次报告中使用 RevoLUtion 来表示 ReLU 对深度学习的贡献，同时使用红色字体高亮了单词中的 ReLU ，非常形象。 Network in NetWork 除了 mini-batch size 外，网络的一层的输入维度为 height * width * channels ，可以通过 polling 操作来减小 height 和 width ，但是怎样减少 channel 的个数呢？ 1 * 1 卷积可以大显身手。当然，如果你愿意也可以用来增加 channel 的个数。 DepthWise convolution 卷积时，并不再是同时对所有的通道进行卷积，而是分别对每个通道使用不同的滤波器进行卷积，得到同等数量的新的 feature maps， 然后使用 1x1 的卷积宽通道进行卷积操作。 不同的通道得到的是不同的特征，需要分别对每个通道进行单独的处理，所以使用 DW ，各个通道之间也可能有关联，所以最后进行 1x1 卷积综合各个通道的特征。 这样不仅大大减少了参数的个数，也加速了网络的计算速度。 网络架构 AlexNet 有大量的超参需要手工调节。 需要仔细设计了什么时候使用卷积层、什么时候使用池化层以及卷积核的大小 VGG 没有太多的超参。虽然有 16 个权重层，但总体结构并不复杂。固定卷积核大小为 3 * 3、步长为 1、same padding，池化层 2 * 2、步长为 2 ；网络的结构很规整：总是几个卷积层后接一个池化层、滤波器的个数不断更新为原来的 2 倍， 从而图像 的宽和高每次池化后都缩减到一半、每组卷积的通道数都增加一倍。 GoogLeNet 采用模块化结构。将 1 * 1 卷积、3 * 3 卷积、5 * 5 卷积、max pooling （需要 same padding ，且步长改为 1 使 得图像的高和宽保持不变）全部在一个网络层中使用，将每一种操作得到的结果堆叠起来得到网络的输出，让网络自己 决定这一层网络到底需要什么操作，而不人工指定该层就是卷积层或者池化层或者全连接层。 网络深度 最初使用 BP 算法的神经网络只有两层；LeNet 进化成了 7 层；AlexNet 8 层；VGG 飞升到 19 层；GoogLeNet 22 层；而 ResNet 使用 skip connection 直接进化到了 152 层，后来成功训练了 1000 层的网络。 Batch Normalization 为了让模型更加容易训练，通常会先将样本进行预处理，其中一个关键的预处理方法就是将样本进行归一化处理。归一化之后样本在不同 的维度分布更加合理，有利于加速模型训练。 为了让后一层网络更容易训练，Batch Normalization 让网络的每一层输出都进行归一化，显著减小了多层之间协调更新的问题，输入的 稳定使得网络的每一层可以单独训练。 很好的正则化方法，何凯明大神说可以替代其他所有的正则化方法。 Batch normalization 是优化深度神经网络中最激动人心的创新之一。另外并不希望所有网络层的输出都是0 均值、方差为 1 ，所以 batch norm 为每个节点增加了均值和方差两个参数来调节归一化结果的分布，这两个参数由网络学习得到。又由于增加了均值这个参数 使得节点原来的偏移参数 b 不再有意义，可以去掉。 可以有两种不同的使用方法：在求取激活函数之前进行归一化，然后再利用激活函数得到该层网络的输出；也可以先计算激活函数的输出， 然后再进行归一化。第一种方法较为常用。 \begin{align*} μ = \frac{1}{m} ∑_i Z[l](i) σ^2 = \frac{1}{m} ∑_i (Z[l](i) - μ)^2 Znorm[l](i) = \frac{Z[l](i) - μ}{\sqrt{σ^2+ε}} {\widetilde{Z}}[l](i) = γ Znorm[l](i) + β \end{align*} 使用 mini-batch 前向传播的时候在计算激活函数之前先使用 batch norm ，然后计算激活函数，继续传播；反向传播时使用和求取权重 参数 W 一样的方法来求取均值和方差参数 \(d\gamma, \ d\beta\) 。在卷积层之后使用需要计算所有 channel 的平均值。 batch norm 使得网络每一层的输出值都得到归一化，归一化到某个分布。这将减小前面层网络参数的变化对后面层权重的影响，因为不 论前面层如何变化，都始终服从某个固定的分布，当前面层的输入变化时，其输出变化不会很大，所以后面的网络层的输入不会变化很大， 从而前面输入的变化对后面层网络权重参数的训练的影响减小，类似 达到了让每层网络参数独立训练的效果 。另外 batch norm 还有 正则化的效果，由于使用 mini-batch 只是所有训练样本的一小部分，所以其均值和方法都含有一定的噪声，每次使用 mini-batch的样 本去训练网络，并用含有噪声的均值和方法去归一化每一层的输出，就类似于 Dropout 随机丢弃网络中神经元节点一样，达到了的正则 化的效果。 测试时一般一次只输入一个样本，而不是像训练时那样，每次使用 mini-batch size 数量的样本。需要使用训练样本来估计网络每一层 输出的均值和方差，并用于测试时使用。一般使用不同的 mini-batch 的各个层输出值的指数加权平均来估计 \begin{align*} {μmean}[l] & = β {μmean}[l] + (1-β) {μ}^{\{i\}[l]} {σmean}2[l] & = β {σmean}2[l] + (1-β) {σ}^{2\{i\}[l]} \end{align*} 疑问：这里求取平均值只是穿越了不同的 mini-batch ，那么不用关系 epoch 吗？是不是取最后一个 epoch 的所有 mini-batch 的平均 效果更好？感觉这个好像就是训练好网络之后，又重新将所有训练样本训练一般一样。吴恩达说两者的效果都不错。这里的平均值次数是 不是应该选的比较大一点？0....</p></div><footer class=entry-footer>3 min&nbsp;·&nbsp;446 words&nbsp;·&nbsp;Kyle Three Stones</footer><a class=entry-link aria-label="post link to 卷积神经网络进化" href=https://kylestones.github.io/hugo-blog/blog/machinelearning/revolution/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>损失函数</h2></header><div class=entry-content><p>为了度量算法关于某个数据集的性能，我们需要损失函数。当算法希望生成比真实值一个较小的数字，那么损失函数中应该体现出现，较 大的输出比较小的输出有更大的惩罚。 Loss: Used to evaluate and diagnose model optimization only. Metric: Used to evaluate and choose models in the context of the project. Mean Squared Error MSE 是经常被使用的损失函数，易于理解，且表现很好。 take the difference between your predictions and the ground truth square it average it out across the whole dataset def MSE(y_predicted, y): squared_error = (y_predicted, y) ** 2 sum_squared_error = np....</p></div><footer class=entry-footer>2 min&nbsp;·&nbsp;398 words&nbsp;·&nbsp;Kyle Three Stones</footer><a class=entry-link aria-label="post link to 损失函数" href=https://kylestones.github.io/hugo-blog/blog/machinelearning/loss-function/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://kylestones.github.io/hugo-blog/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/page/3/>« Prev</a>
<a class=next href=https://kylestones.github.io/hugo-blog/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/page/5/>Next »</a></nav></footer></main><footer class=footer><span>&copy; 2022 <a href=https://kylestones.github.io/hugo-blog>Org Mode</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z" /></svg></a><script>let menu=document.getElementById('menu')
if(menu){menu.scrollLeft=localStorage.getItem("menu-scroll-position");menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft);}}
document.querySelectorAll('a[href^="#"]').forEach(anchor=>{anchor.addEventListener("click",function(e){e.preventDefault();var id=this.getAttribute("href").substr(1);if(!window.matchMedia('(prefers-reduced-motion: reduce)').matches){document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({behavior:"smooth"});}else{document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();}
if(id==="top"){history.replaceState(null,null," ");}else{history.pushState(null,null,`#${id}`);}});});</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){if(document.body.scrollTop>800||document.documentElement.scrollTop>800){mybutton.style.visibility="visible";mybutton.style.opacity="1";}else{mybutton.style.visibility="hidden";mybutton.style.opacity="0";}};</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{if(document.body.className.includes("dark")){document.body.classList.remove('dark');localStorage.setItem("pref-theme",'light');}else{document.body.classList.add('dark');localStorage.setItem("pref-theme",'dark');}})</script></body></html>